\section{Challenges}
Developing \projx system poses significant challenges in both research and engineering. In this section, we will highlight these challenges, and present our ideas to address them.

\subsection{Research Challenges}



\subsubsection{Instant Feedback Loops}

Since data cleaning processing is often time consuming, to avoid users to feel ``left in the dark" during the process, our system can provide instant feedback loops and make users to get a sense that how data cleaning will change the data and affect the analysis results. We achieve this goal based on the following three ideas. 

\vspace{.5em}

{\noindent \bf Sampling-and-Cleaning:} \projx allows users to clean a small sample of data, which is typically much cheaper and faster than cleaning the entire data. With the cleaned sample, the system is able to inform users the changes of their original analysis results, with the help of new query processing methods for dirty data~\cite{wang1999sample}. For example, suppose one collects a restaurant dataset, and runs some aggregation queries on the dataset, e.g., computing the number of the restaurants in San Fransisco and getting a query result of 12000. But, when looking at the dataset, she finds that there are many duplicate restaurants in the dataset, and some restaurants' locations are misspelled (e.g., S\underline{e}n Fransisco). She can use our system to create a sample of the data, and then apply a data cleaning procedure to the sample. After the sample is cleaned, our system can estimate the impact of data cleaning on her original query results, and return her corrected answers with confidence intervals, e.g., $5000\pm300$. Intuitively, this result means that if the same data-cleaning procedure is applied to the full dataset, the number of the restaurants in San Fransisco will be within $[4700, 5300]$. 

\vspace{.5em}
{\noindent \bf Crowdsourcing and Active Learning:} Our second idea to provide instant feedbacks is to reduce the running time of data cleaning operations. We find that many data cleaning operations (e.g., entity resolution~\cite{DBLP:journals/pvldb/YakoutENOI11}, data repairing~\cite{DBLP:journals/pvldb/MozafariSFJM14} require to use active learning to train a machine learning model from the crowd, and then apply the model to clean the data. The completion time of the process largely depends on how fast to get labels from the crowd. A naive implementation is to send a set of tasks to a crowdsourcing platform, and allow arbitrary crowd workers to label them. This method can be very slow since in a real-world crowdsourcing platform, it is very likely that there are some workers who do tasks much slower than others. When such workers are doing our labeling tasks, we have to wait a lot of time until they finish. In the active learning component of our system, we address this problem by maintaining a pool of crowd workers and keeping track of the characteristics (i.e., quality and speed) of each worker in the pool. We develop a task routing strategy that can avoid assigning tasks to slow workers and significantly reduce the time that is required to train a machine learning model from the crowd.



\vspace{.5em}
{\noindent \bf Asynchronous Data Cleaning:} To provide more fine-grained feedbacks during a data cleaning process, our system allows users to execute a data cleaning operation asynchronously. The benefit of this feature is that users can monitor how data cleaning will change the data progressively. For example, suppose a user specifies an entity resolution operation that uses active learning to train a classifier to detect duplicates in a dataset. Since active learning is an iterative learning process, in each iteration it can train a classifier. With the asynchrony feature of our system, users can monitor the varying performance of the classifier, which enables them to have a better understanding of the cleaning process.


%Even cleaning a sample of data, data cleaning can still take a lot of time. This is especially true when it requires humans to clean the data. 






\subsubsection{Hot Swapping}
Data cleaning is often domain-specific. It's hard to have a general data-cleaning pipeline with fixed parameters and physical operations that works well for any given dataset. Therefore, it is very common that people apply a data-cleaning pipeline to a dataset and then realize the cleaning results does not satisfy their requirements (e.g.,  some part of the data is mistakenly cleaned or a certain type of data error is not captured). In this situation, they would like to modify the data-cleaning pipeline, by adjusting parameters or replacing one physical operation with another, and then apply the new pipeline to clean the data. The idea of hot swapping is to make this process efficient without incurring the overhead of re-executing the entire pipeline. In the following, we will briefly how our system can efficiently support the hot swapping, and how to recommend suitable parameters and physical operations for users to swap. 


\vspace{.5em}

{\noindent \bf Mechanism:} caching and lineage

\vspace{.5em}

{\noindent \bf Policy:} some fancy algorithms





\iffalse
\subsection{Research Challenges}

Architecturally, we separate crowd sourcing and automated data cleaning.
There is a crowd server that acts as a layer of indirection between the Spark codebase and crowd sourcing APIs.

\team{Describe Research Challenges.  To what extend can we actually do
optimization given the physical operators?  Unlike relalgebra, the physical operators here are
not interchangable!}



\subsection{Learning Parameters From Example}
In simple cases, it might be easy to use domain knowledge to select and tune physical operators. 
In more complex cases, it might be easier to specify a sample of dirty and clean data instead of the function.
It may also not be feasible to have the crowd clean the entire dataset.
In these cases, we want to learn a statistical model from which we can extrapolate those responses to the rest 
of the data.

In our current implementation of \projx, we pose this learning problem as classification problems.
In general, these parameter functions can be quite complex and this is a simplification of the learning problem.
The choice of classifier and featurization is upto the user. 
We currently support Support Vector Machines and Decision Trees with a featurization library that includes common text processing features.

\vspace{0.5em}

\noindent \textsf{Filter(R, $\mathcal{T}^+$, $\mathcal{T}^-$)}: Given a set of positive training examples $\mathcal{T}^+$ (i.e, $r$ that satisfy the condition) and
negative training examples $\mathcal{T}^-$ (i.e, r that do not satisfy the condition), we learn a classifier that predicts whether a record satisfies the condition. 

\vspace{0.5em}

\noindent \textsf{Extract(R, a, $\mathcal{T}$)} We restrict the learned problem setting to delimited extraction. Given a set of training examples $R(a)$ and the output $v_1,v_2,...,v_k$, we learn a classifier to predict which characters in $R(a)$ are delimiters based on the tokens in the string.

\vspace{1em}

To acquire the samples of clean data, uniform sampling may not be the best strategy.
For example, if there examples of dirty data are very rare, we will not be able to learn a model.
We implement a technique called Active Learning to sample.
Active Learning selects the most informative examples based on the current model so far.
We use an Active Learning algorithm called uncertainty sampling to do this.




\subsection{Inspection}

Data cleaning requires inspection -- user wants to see how the dataset
has been "cleaned"  through the pipeline.  What does that even mean?

\subsection{Dynamic Re-optimization}

Crowd means want to swap in or out operators at run time.


\subsection{Lineage}

\noindent\textbf{Lineage: }
We track the lineage of rows using a primary key.
Users are not allowed to modify this primary key with any operations.
This allows us to apply operations like transitive closure even after projection since we have a unique identifier for each row.

\vspace{0.5em}
\noindent \textbf{Example: } Suppose, we are interested in deduplication of unstructured data. Then, we could apply the following logical operations.
We first apply an \textsf{Extract} operation to extract the unstructured data into columns. If some of the columns are inconsistent in their representation,
we apply \textsf{Project} to those columns that are inconsistent. We can then take a \textsf{SimilarityJoin} to group rows that are similar, and finally
we resolve those differences with \textsf{TransitiveClosure}.
\fi


