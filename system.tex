\section{Execution Layer}
The previous section describes an abstract formalization of the data cleaning API.
We require an additional step to take that formalization and execute it.

\subsection{Spark Utilities}

\vspace{0.5em}

\noindent\textbf{Connected Components: } One issue with the data cleaning operators specified in the previous section is transitive closure. For example, in our social media analysis demonstration, we might merge the tags ``Water" to ``Environment" and ``Drought" to ``Water". This creates a transitivity issue. To resolve this problem, we apply a distributed using a distributed gather-apply-scatter connected components algorithm in GraphX. We can associate these merges with edges in a graph.

\noindent\textbf{Persistence and Asynchrony: } We provide a Scala \textsf{Future} based framework to allow for asynchronous execution of data cleaning operations.
In this execution model, the user defines a data cleaning operation and executes it in the background.
We provide library routines to persist intermediate results.
We further provide a method to add callback notifications to the the asynchronously executed operation.
We also keep track of meta data including lineage for each record through the use of primary keys.

\noindent\textbf{Approximate Query Processing: }
The challenge with asynchrony is that the entire dataset might not be cleaned at query time. To address this challenge, 
we provide an approximate query processing API that allows users to answer aggregate queries with confidence intervals 
on intermediate results.

\begin{example}[Social Media Analysis]
Analysis question (1) which topics are the most popular, and (2) which topics are the most popular among Democrats/Republicans,
are SQL aggregate queries.
\end{example}

\subsection{Optimizations}
We also provide some preset features and similarity functions that allow for optimizations.
\projx provides a library of the following commonly used similarity functions: \textsf{JaccardSimilarity}, \textsf{DiceSimilarity},
\textsf{CosineSimilarity}, \textsf{OverlapSimilarity}, and \textsf{EditDistance}.
A naive implementation of a Similarity Join is to take the cartesian product and then filter all pairs of record of similarity greater than $t$.
However, the implemented similarity functions are all symmetric and the similarity function is maximized when $r = p$.
So it suffices to compute a similarity $\theta$-join instead of the full cartesian product.
We can further add an optimization called prefix filtering to further reduce the number of similarity function evaluations.
In prefix filtering, we prune pairs that cannot possibly meet the threshold $t$ based on the number of tokens that overlap which can be determined with an inverted index.






